# Regular Show AI

## What is this
This project is the server component of a project a friend and I made. This server creates scenes based on the cartoon Regular Show with AI-generated conversations with corresponding audio. Once the server has generated the conversation and audio, a JSON file is created with all data about the scene for a Unity game to query and implement with 3D models of the characters to act out.

## How it works
When running the executable there are two arguments. 

`regular-show-ai.exe /path/to/scenes [-g]`

The first argument is the path to your scenes folder on disk. The second is the argument if you want to generate more scenes. The scenes will be generated every minute.

Once you run the executable, it reads from disk which scenes you have available. You can visit `localhost:3000/api/scene` to pick a random scene. Each time you request that link, you get another random scene. Each scene that is requested is then discarded until you've requested all possible scenes.

## Generating new scenes
if the `-g` flag is provided when running the executable, scenes will be generated while also running the server. Every time a new scene is generated, it is eligible to be picked by the api. 

Scenes are generated by prompting ChatGPT with a topic. Topics are picked from `ideas.txt`. The server will pop off the first topic and use it. Each topic should be separated by a new-line delimiter. Once the conversation is completed, the program will create a new directory for the scene and generate a `metadata.json` file. Once the directory and conversation is generated, each turn in the conversation is then put through the Uberduck api to generate the audio. Once the audio is done being made, the audio files are downloaded to the `audio` directory inside the new scene directory. Each audio file is named from the index of where it should be played in the conversation starting at 0.

## metadata.json
Each scene directory includes a `metadata.json` file providing integral data for Unity to handle. Each file is structured as follows:

```json
{
    "ID": 1,
    "Characters": 3,
    "Conversations": []
}
```

### Characters
The characters field is a bitfield representing which characters are in the scene.
| Bit | Value | Character |
| --- | ----- | --------- |
| 1   | 1     | Mordecai  |
| 2   | 2     | Rigby     |
| 3   | 4     | Pops      |
| 4   | 8     | Beson     |
| 5   | 16    | Muscle Man |
| 6   | 32    | Doe        |

So the `3`, or `0b11`, in the example above would indicate that Mordecai and Rigby are in that conversation. [John] Doe is the fallback character if something went wrong with identifying the current character talking. In this case, just pick a random character.

### Conversations
The conversations field is structed as follows:

```json
{
    "Character": 1,
    "Content": "Hello, world"
}
```

The `Character` field is a bitfield as described above representing which character is talking. The `Content` field is what the character is supposed to be currently saying. The audio files that go with each part of the conversation is in the `audio` directory named with the index in the `Conversations` array with the suffix `.wav`.
